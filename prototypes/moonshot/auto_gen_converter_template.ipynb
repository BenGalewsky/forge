{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_flag = \"## Metadata\"\n",
    "end_flag= \"## End metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_doc = '''dataset_metadata: {\n",
    "    \"mdf-title\": , # title\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "import sys\n",
      "from validation.validator import Validator\n",
      "\n",
      "# VERSION 0.2.0\n",
      "\n",
      "# This is the template for new converters. It is not a complete converter. Incomplete parts are labelled with \"TODO\"\n",
      "# Arguments:\n",
      "#   input_path (string): The file or directory where the data resides.\n",
      "#       NOTE: Do not hard-code the path to the data in the converter, so that the converter is portable.\n",
      "#   metadata (string or dict): The path to the JSON dataset metadata file, a dict or json.dumps string containing the dataset metadata, or None to specify the metadata here. Default None.\n",
      "#   verbose (bool): Should the script print status messages to standard output? Default False.\n",
      "#       NOTE: The converter should have NO output if verbose is False, unless there is an error.\n",
      "def convert(input_path, metadata=None, verbose=False):\n",
      "    if verbose:\n",
      "        print(\"Begin converting\")\n",
      "\n",
      "    # Collect the metadata\n",
      "    # TODO: Make sure the metadata is present in some form.\n",
      "    # Fields can be:\n",
      "    #    REQ (Required, must be present)\n",
      "    #    RCM (Recommended, should be present if possible)\n",
      "    #    OPT (Optional, can be present if useful)\n",
      "    if not metadata:\n",
      "        ## Metadata:Dataset\n",
      "        dataset_metadata: {\n",
      "    \"mdf-title\": , # title\n",
      "}\n",
      "        ## End metadata\n",
      "    elif type(metadata) is str:\n",
      "        try:\n",
      "            dataset_metadata = json.loads(metadata)\n",
      "        except Exception:\n",
      "            try:\n",
      "                with open(metadata, 'r') as metadata_file:\n",
      "                    dataset_metadata = json.load(metadata_file)\n",
      "            except Exception as e:\n",
      "                sys.exit(\"Error: Unable to read metadata: \" + repr(e))\n",
      "    elif type(metadata) is dict:\n",
      "        dataset_metadata = metadata\n",
      "    else:\n",
      "        sys.exit(\"Error: Invalid metadata parameter\")\n",
      "\n",
      "\n",
      "\n",
      "    # Make a Validator to help write the feedstock\n",
      "    # You must pass the metadata to the constructor\n",
      "    # Each Validator instance can only be used for a single dataset\n",
      "    # If the metadata is incorrect, the constructor will throw an exception and the program will exit\n",
      "    dataset_validator = Validator(dataset_metadata)\n",
      "\n",
      "\n",
      "    # Get the data\n",
      "    # TODO: Write the code to convert your dataset's records into JSON-serializable Python dictionaries\n",
      "    #    Each record should be exactly one dictionary\n",
      "    #    You must write your records using the Validator one at a time\n",
      "    #    It is recommended that you use a parser to help with this process if one is available for your datatype\n",
      "\n",
      "    # Each record also needs its own metadata\n",
      "    for record in your_records:\n",
      "        # TODO: Fill in these dictionary fields for each record\n",
      "        # Fields can be:\n",
      "        #    REQ (Required, must be present)\n",
      "        #    RCM (Recommended, should be present if possible)\n",
      "        #    OPT (Optional, can be present if useful)\n",
      "        ## Metadata:Record\n",
      "        dataset_metadata: {\n",
      "    \"mdf-title\": , # title\n",
      "}\n",
      "        ## End metadata\n",
      "\n",
      "        # Pass each individual record to the Validator\n",
      "        result = dataset_validator.write_record(record_metadata)\n",
      "\n",
      "        # Check if the Validator accepted the record, and print a message if it didn't\n",
      "        # If the Validator returns \"success\" == True, the record was written successfully\n",
      "        if result[\"success\"] is not True:\n",
      "            print(\"Error:\", result[\"message\"])\n",
      "\n",
      "\n",
      "    # TODO: Save your converter as [mdf-source_name]_converter.py\n",
      "    # You're done!\n",
      "    if verbose:\n",
      "        print(\"Finished converting\")\n",
      "\n",
      "\n",
      "# Optionally, you can have a default call here for testing\n",
      "# It is not guaranteed that this is the way the converter will be called in actual use\n",
      "# This is why the 'input_path' should not be hard-coded, and the script should have no output if 'verbose' is False\n",
      "if __name__ == \"__main__\":\n",
      "    convert()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_script.py\") as test_in:\n",
    "    doc = \"\"\n",
    "    indent = \"    \"\n",
    "    pause = False\n",
    "    for line in test_in:\n",
    "        if pause:\n",
    "            if end_flag in line:\n",
    "                doc += line\n",
    "                pause = False\n",
    "        elif start_flag in line:\n",
    "            doc += line\n",
    "            line_parts = line.split(\":\")\n",
    "            base_indent = line_parts[0].replace(start_flag, \"\").strip(\"\\n\")\n",
    "            node_type = line_parts[1]\n",
    "            doc +=  base_indent + dataset_doc\n",
    "            pause = True\n",
    "        else:\n",
    "            doc += line\n",
    "print(doc)\n",
    "#with open(\"test_output.py\", 'w') as test_out:\n",
    "#    test_out.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
